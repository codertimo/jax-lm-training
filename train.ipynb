{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-02e04c3b1bfb723e\n",
      "WARNING:datasets.builder:Reusing dataset parquet (/home/codertimo/.cache/huggingface/datasets/parquet/default-02e04c3b1bfb723e/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def batch_collate_fn(data_list):\n",
    "    batch_dict = {key:[] for key in data_list[0].keys()}\n",
    "    for data in data_list:\n",
    "        for key, value in data.items():\n",
    "            batch_dict[key].append(value)\n",
    "    return {key: jnp.array(value) for key, value in batch_dict.items()}\n",
    "\n",
    "batch_size = 8\n",
    "dataset = Dataset.from_parquet(\"data/wikitext*\")\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, drop_last=True, collate_fn=batch_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_gpt_config = {\n",
    "  \"_num_labels\": 1,\n",
    "  \"activation_function\": \"gelu_new\",\n",
    "  \"architectures\": [\n",
    "    \"GPT2LMHeadModel\"\n",
    "  ],\n",
    "  \"attn_pdrop\": 0.1,\n",
    "  \"bos_token_id\": 50256,\n",
    "  \"embd_pdrop\": 0.1,\n",
    "  \"eos_token_id\": 50256,\n",
    "  \"initializer_range\": 0.02,\n",
    "  \"layer_norm_epsilon\": 1e-05,\n",
    "  \"model_type\": \"gpt2\",\n",
    "  \"n_ctx\": 1024,\n",
    "  \"n_embd\": 768,\n",
    "  \"n_head\": 12,\n",
    "  \"n_layer\": 6,\n",
    "  \"n_positions\": 1024,\n",
    "  \"resid_pdrop\": 0.1,\n",
    "  \"vocab_size\": 50257\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.gpt2.modeling_flax_gpt2 import FlaxGPT2LMHeadModel, GPT2Config\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "model_config = GPT2Config.from_pretrained(\"gpt2\")\n",
    "model = FlaxGPT2LMHeadModel(model_config, input_shape=(8, 256), seed=0, dtype=jnp.dtype(\"bfloat16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "epochs = 1\n",
    "training_seed = 0\n",
    "num_train_steps = len(dataloader) * epochs\n",
    "\n",
    "rng = jax.random.PRNGKey(training_seed)\n",
    "rng, dropout_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.training import train_state\n",
    "from flax.training.common_utils import get_metrics, onehot, shard\n",
    "import optax\n",
    "\n",
    "linear_decay_lr_schedule_fn = optax.linear_schedule(init_value=learning_rate, end_value=0, transition_steps=num_train_steps)\n",
    "adamw = optax.adamw(learning_rate=linear_decay_lr_schedule_fn, b1=0.9, b2=0.98, eps=1e-8, weight_decay=0.01)\n",
    "state = train_state.TrainState.create(apply_fn=model.__call__, params=model.params, tx=adamw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(state, batch, dropout_rng):\n",
    "    dropout_rng, new_dropout_rng = jax.random.split(dropout_rng, num=2)\n",
    "\n",
    "    def loss_fn(params):\n",
    "        labels = batch.pop(\"labels\")\n",
    "        pred_logits = state.apply_fn(**batch, params=params, dropout_rng=dropout_rng, train=True)[0]\n",
    "        return optax.softmax_cross_entropy(pred_logits, onehot(labels, pred_logits.shape[-1])).mean()\n",
    "    \n",
    "    grad_fn = jax.value_and_grad(loss_fn)\n",
    "    loss, grad = grad_fn(state.params)\n",
    "    grad = jax.lax.pmean(grad, \"batch\")\n",
    "\n",
    "    new_state = state.apply_gradients(grads=grad)\n",
    "    metrics = {\"loss\": loss, \"learning_rate\": linear_decay_lr_schedule_fn(state.step)}\n",
    "    metrics = jax.lax.pmean(metrics, axis_name=\"batch\")\n",
    "\n",
    "    return new_state, metrics, new_dropout_rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': ShardedDeviceArray([0.00027987], dtype=float32), 'loss': ShardedDeviceArray([6.676178], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00025973], dtype=float32), 'loss': ShardedDeviceArray([5.823189], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.0002396], dtype=float32), 'loss': ShardedDeviceArray([5.9843597], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00021946], dtype=float32), 'loss': ShardedDeviceArray([5.8715134], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00019933], dtype=float32), 'loss': ShardedDeviceArray([4.9384155], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00017919], dtype=float32), 'loss': ShardedDeviceArray([5.41835], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00015906], dtype=float32), 'loss': ShardedDeviceArray([5.679558], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00013893], dtype=float32), 'loss': ShardedDeviceArray([6.3515854], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([0.00011879], dtype=float32), 'loss': ShardedDeviceArray([5.85598], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([9.8657714e-05], dtype=float32), 'loss': ShardedDeviceArray([5.9031754], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([7.8523495e-05], dtype=float32), 'loss': ShardedDeviceArray([4.612152], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([5.838926e-05], dtype=float32), 'loss': ShardedDeviceArray([6.747238], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([3.8255024e-05], dtype=float32), 'loss': ShardedDeviceArray([5.6098137], dtype=float32)}\n",
      "{'learning_rate': ShardedDeviceArray([1.8120809e-05], dtype=float32), 'loss': ShardedDeviceArray([5.1105385], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import flax\n",
    "\n",
    "p_train_step = jax.pmap(train_step, \"batch\")\n",
    "state = flax.jax_utils.replicate(state)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    dropout_rngs = jax.random.split(rng, num=jax.local_device_count())\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = shard(batch)\n",
    "        state, train_metric, dropout_rngs = p_train_step(state, batch, dropout_rngs)\n",
    "        \n",
    "        if i > 0 and i % 10 == 0:\n",
    "            print(train_metric)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f30fae31e7aae18a92efe6242e667e6b9dbe445fb96d835474b65b1849ce26d9"
  },
  "kernelspec": {
   "display_name": "Python 3.7.5 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
